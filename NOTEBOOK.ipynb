{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506e0318",
   "metadata": {},
   "source": [
    "# Important Libraries to Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff58656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, RandomOverSampler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375551e7",
   "metadata": {},
   "source": [
    "# Machine Learning Model Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a772b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, datafile = \"airline_sentiment_analysis.csv\"):\n",
    "        self.data = pd.read_csv(datafile)\n",
    "        self.porter = PorterStemmer()\n",
    "        self.tfidf = TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None)\n",
    "        self.kernel = 'rbf'\n",
    "        self.degree=3\n",
    "        self.pred_model=None\n",
    "        self.stopword=False\n",
    "        self.undersampling =0\n",
    "# This function use to spliting train and test file as well as used to do oversampling by giving appropriate parameter\n",
    "    def split(self, test_size, Oversampling=0, oversample_type='ros'):\n",
    "        y = self.data['airline_sentiment']\n",
    "        X = self.data['text']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "        if Oversampling==1:\n",
    "            if oversample_type == 'ros':\n",
    "                ros = RandomOverSampler(sampling_strategy=1)\n",
    "                X_over, y_over = ros.fit_resample(self.X_train.values.reshape(-1, 1), self.y_train)\n",
    "                self.X_train=X_over.reshape( -1)\n",
    "                self.y_train = y_over\n",
    "        if self.undersampling ==1:\n",
    "            rus = RandomUnderSampler(sampling_strategy=1)\n",
    "            X_over, y_over = rus.fit_resample(X_train.values.reshape(-1, 1), y_train)\n",
    "            self.X_train=X_over.reshape( -1)\n",
    "            self.y_train = y_over\n",
    "\n",
    "# Function for default tokenizer i.e spliting by spaces \n",
    "    def tokenizer(self, text):\n",
    "        return text.split()\n",
    "# Fuction for Tokenizer using potter stemmer\n",
    "    def tokenizer_porter(self, text):\n",
    "        return [self.porter.stem(word) for word in text.split()]\n",
    "# Function including basic text preprocessing\n",
    "    def preprocessor(self, text):\n",
    "        # Remove HTML markup\n",
    "        text = re.sub('<[^>]*>', '', text)\n",
    "        # Remove Website  markup\n",
    "        text = re.sub(r'https?:\\/\\/\\S+', '' , text)\n",
    "        text = re.sub(r'\\w*\\@*\\w*\\.(com)\\w*', '', text)\n",
    "        text = re.sub(r'^(emailmailto:)\\w*\\.*\\w+\\@*\\w+\\.com',' ',text)\n",
    "        # remove @ mentions\n",
    "        text = re.sub(r\"@([A-Za-z]+)\", \"\", text)\n",
    "        # remove numbers\n",
    "        text = re.sub(\"[0-9]+\", \"\", text)\n",
    "        #  stopwords\n",
    "        if self.stopword==True:\n",
    "            text = \" \".join([word for word in str(text).split() if word not in self.STOPWORDS])\n",
    "        # Save emoticons for later appending\n",
    "        # emoticons helps to find the sentiment\n",
    "        emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "        # Remove any non-word character and append the emoticons,\n",
    "        # removing the noise character for standarization. Convert to lower case\n",
    "        text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "        return text\n",
    "    # I have created a pipeline were frist it will call functions for preprocessing and TfidfVectorizer\n",
    "    # Then it will call the ML Algorithms.\n",
    "    def logisticregression(self):\n",
    "        param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__tokenizer': [self.tokenizer, self.tokenizer_porter],\n",
    "               'vect__preprocessor': [None, self.preprocessor],\n",
    "               'clf__penalty': ['l1','l2'],\n",
    "               'clf__C': [1.0]},\n",
    "              ]\n",
    "\n",
    "        lr_pipe = Pipeline([('vect', self.tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "        lr_clf = GridSearchCV(lr_pipe, param_grid,scoring='accuracy',cv=5,verbose=1,n_jobs=-1)\n",
    "        return lr_clf\n",
    "    \n",
    "    def support_vector_machine(self, kernal, degree):\n",
    "        param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__tokenizer': [self.tokenizer, self.tokenizer_porter],\n",
    "               'vect__preprocessor': [None, self.preprocessor]},\n",
    "              ]\n",
    "\n",
    "        cvm_pipe = Pipeline([('vect', self.tfidf),\n",
    "                     ('clf',  svm.SVC(C=9.0,kernel=self.kernel, degree=self.degree,random_state=42))])\n",
    "\n",
    "        svm_clf = GridSearchCV(cvm_pipe, param_grid,scoring='accuracy',cv=5)\n",
    "        return svm_clf\n",
    "    # Here I have change the TFIDF model I have used TfidfTransformer \n",
    "    # here I am getting some error while using TfidfVectorizer So I have changed pipeliine little bit \n",
    "    # add an vectorizer before TFIDF\n",
    "    # Pipeline was vectorizer => TfidfTransformer => classifier to make things easier\n",
    "    def Multinomial_Naive_Bayes(self):\n",
    "        text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "        tuned_parameters = {\n",
    "                'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "                'tfidf__use_idf': (True, False),\n",
    "                'tfidf__norm': ('l1', 'l2'),\n",
    "                'clf__alpha': [1, 1e-1, 1e-2]\n",
    "            }\n",
    "        clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring='accuracy')\n",
    "        return clf\n",
    "    # this function is basically used for fitting All above mentioned Machine learning Model\n",
    "    # Used for Calling function and saving best estimator.\n",
    "    def fit(self,model):\n",
    "        if model == 'svm':\n",
    "            clf = self.support_vector_machine('linear',3)\n",
    "            self.model = clf.fit(self.X_train, self.y_train)\n",
    "        if model == 'lr':\n",
    "            clf = self.logisticregression()\n",
    "            self.model = clf.fit(self.X_train, self.y_train)\n",
    "        if model == 'MNB':\n",
    "            clf = self.Multinomial_Naive_Bayes()\n",
    "            self.model =clf.fit(self.X_train, self.y_train)\n",
    "        self.pred_model = self.model.best_estimator_\n",
    "        return self.model.best_estimator_\n",
    "    # Here I am Using Precision, Recall, F1 Score and Also return Accuracy but Used F1 Score as METRIC\n",
    "    def accuracy(self,clf):\n",
    "        print('Accuracy in test: %.3f' % clf.score(self.X_test, self.y_test))\n",
    "        y_pred = clf.predict(self.X_test)\n",
    "        tn, fp, fn, tp=confusion_matrix(self.y_test, y_pred).ravel()\n",
    "        print('true Positive '% tp)\n",
    "        print('true Negative '% tp)\n",
    "        print('False Positive '% tp)\n",
    "        print('False Negative '% tp)\n",
    "        print('Macro Precision Recall and F1 Score in test:' )\n",
    "        print(precision_recall_fscore_support(self.y_test, y_pred, average='macro'))\n",
    "        \n",
    "        \n",
    "    # Inference function used to find sentiment anaslysis for given Input String\n",
    "    def predict(self, text):\n",
    "        text = self.preprocessor(text)\n",
    "        return self.pred_model.predict([text])\n",
    "    # Function used to Load the model\n",
    "    def load(self, filename='test_data1.pkl'):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.pred_model = pickle.load(f)\n",
    "    # Function used to Load the model\n",
    "    def save(self, filename='test_data1.pkl'):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.pred_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c655702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in test: 0.900\n",
      "true positive \n",
      "Macro Precision Recall and F1 Score in test:\n",
      "(0.8779789239461648, 0.7971823008051886, 0.8285923562290807, None)\n",
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.split(0.3,1)\n",
    "clf = model.fit('MNB')\n",
    "model.accuracy(clf)\n",
    "print(model.predict(\"bad airway\"))\n",
    "# model.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6bcb9f",
   "metadata": {},
   "source": [
    "Multinomial_Naive_Bayes:\n",
    "ROS : (0.8779789239461648, 0.7971823008051886, 0.8285923562290807, None) Accuracy in test: 0.900\n",
    "Simple: (0.9049782953020512, 0.7948925168981034, 0.8345640249974828, None) Accuracy in test: 0.906\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc422",
   "metadata": {},
   "source": [
    "SVM:\\\n",
    "ROS: (0.9137339444555155, 0.8508839047294203, 0.8774770551417379, None) Accuracy in test: 0.926\\\n",
    "Simple: (0.9098036549451257, 0.8519102359639985, 0.8767087962049738, None) Accuracy in test: 0.925"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63add568",
   "metadata": {},
   "source": [
    "Logistic REGRESSION:\\\n",
    "ROS: (0.8459922550527823, 0.8674373369470025, 0.8559969305296486, None)\\\n",
    "Simple: (0.9149278679494364, 0.813249198754882, 0.851406139465841, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66fd416",
   "metadata": {},
   "source": [
    "# Inference \n",
    "Steps used to Load and Predict on any string\\\n",
    "model1 = Model()\\\n",
    "model1.load()\\\n",
    "model1.predict(\"bar airline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a48a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
